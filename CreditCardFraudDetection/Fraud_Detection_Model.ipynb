{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "credit_card_data = pd.read_csv('creditcard.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = credit_card_data.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_data = pd.get_dummies(shuffled_data, columns=['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = (one_hot_data - one_hot_data.min()) / (one_hot_data.max() - one_hot_data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = normalized_data.drop(['Class_0', 'Class_1'], axis=1)\n",
    "df_y = normalized_data[['Class_0', 'Class_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_X, ar_y = np.asarray(df_X.values, dtype='float32'), np.asarray(df_y.values, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(ar_X))\n",
    "(raw_X_train, raw_y_train) = (ar_X[:train_size], ar_y[:train_size])\n",
    "(raw_X_test, raw_y_test) = (ar_X[train_size:], ar_y[train_size:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of fraudulent transactions:  0.001727485630620034\n"
     ]
    }
   ],
   "source": [
    "count_legit, count_fraud = np.unique(credit_card_data['Class'], return_counts=True)[1]\n",
    "fraud_ratio = float(count_fraud / (count_legit + count_fraud))\n",
    "print('Percent of fraudulent transactions: ', fraud_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighting = 1 / fraud_ratio\n",
    "raw_y_train[:, 1] = raw_y_train[:, 1] * weighting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avinash.t\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimensions = ar_X.shape[1]\n",
    "output_dimensions = ar_y.shape[1]\n",
    "num_layer_1_cells = 100\n",
    "num_layer_2_cells = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_node = tf.placeholder(tf.float32, [None, input_dimensions], name='X_train')\n",
    "y_train_node = tf.placeholder(tf.float32, [None, output_dimensions], name='y_train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_node = tf.constant(raw_X_test, name='X_test')\n",
    "y_test_node = tf.constant(raw_y_test, name='y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_1_node = tf.Variable(tf.zeros([input_dimensions, num_layer_1_cells]), name='weight_1')\n",
    "biases_1_node = tf.Variable(tf.zeros([num_layer_1_cells]), name='biases_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_2_node = tf.Variable(tf.zeros([num_layer_1_cells, num_layer_2_cells]), name='weight_2')\n",
    "biases_2_node = tf.Variable(tf.zeros([num_layer_2_cells]), name='biases_2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_3_node = tf.Variable(tf.zeros([num_layer_2_cells, output_dimensions]), name='weight_3')\n",
    "biases_3_node = tf.Variable(tf.zeros([output_dimensions]), name='biases_3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(input_tensor):\n",
    "    layer1 = tf.nn.sigmoid(tf.matmul(input_tensor, weight_1_node) + biases_1_node)\n",
    "    layer2 = tf.nn.dropout(tf.nn.sigmoid(tf.matmul(layer1, weight_2_node) + biases_2_node), 0.85)\n",
    "    layer3 = tf.nn.softmax(tf.matmul(layer2, weight_3_node) + biases_3_node)\n",
    "    return layer3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_prediction = network(X_train_node)\n",
    "y_test_prediction = network(X_test_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\avinash.t\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:691: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.losses.softmax_cross_entropy(y_train_node, y_train_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.005).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(actual, predicted):\n",
    "    actual = np.argmax(actual, 1)\n",
    "    predicted = np.argmax(predicted, 1)\n",
    "    return (100 * np.sum(np.equal(predicted, actual)) / predicted.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Current loss: 1.3983 Elapsed time: 11.34 seconds\n",
      "Current accuracy: 0.16%\n",
      "Epoch: 10 Current loss: 1.3973 Elapsed time: 8.44 seconds\n",
      "Current accuracy: 31.79%\n",
      "Epoch: 20 Current loss: 1.3760 Elapsed time: 10.57 seconds\n",
      "Current accuracy: 7.90%\n",
      "Epoch: 30 Current loss: 1.2771 Elapsed time: 11.06 seconds\n",
      "Current accuracy: 67.31%\n",
      "Epoch: 40 Current loss: 1.1020 Elapsed time: 10.28 seconds\n",
      "Current accuracy: 96.76%\n",
      "Epoch: 50 Current loss: 0.9816 Elapsed time: 10.06 seconds\n",
      "Current accuracy: 98.73%\n",
      "Epoch: 60 Current loss: 0.9070 Elapsed time: 9.13 seconds\n",
      "Current accuracy: 98.54%\n",
      "Epoch: 70 Current loss: 0.8739 Elapsed time: 10.79 seconds\n",
      "Current accuracy: 99.39%\n",
      "Epoch: 80 Current loss: 0.8574 Elapsed time: 9.28 seconds\n",
      "Current accuracy: 99.32%\n",
      "Epoch: 90 Current loss: 0.8449 Elapsed time: 10.92 seconds\n",
      "Current accuracy: 99.55%\n",
      "Final accuracy: 99.40%\n",
      "Final fraud specific accuracy: 80.22%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "with tf.Session() as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        _, cross_entropy_score = session.run([optimizer, cross_entropy],\n",
    "                                             feed_dict={X_train_node: raw_X_train, y_train_node: raw_y_train})\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            timer = time.time() - start_time\n",
    "\n",
    "            print('Epoch: {}'.format(epoch), 'Current loss: {0:.4f}'.format(cross_entropy_score),\n",
    "                  'Elapsed time: {0:.2f} seconds'.format(timer))\n",
    "\n",
    "            final_y_test = y_test_node.eval()\n",
    "            final_y_test_prediction = y_test_prediction.eval()\n",
    "            final_accuracy = calculate_accuracy(final_y_test, final_y_test_prediction)\n",
    "            print(\"Current accuracy: {0:.2f}%\".format(final_accuracy))\n",
    "\n",
    "    final_y_test = y_test_node.eval()\n",
    "    final_y_test_prediction = y_test_prediction.eval()\n",
    "    final_accuracy = calculate_accuracy(final_y_test, final_y_test_prediction)\n",
    "    print(\"Final accuracy: {0:.2f}%\".format(final_accuracy))\n",
    "\n",
    "final_fraud_y_test = final_y_test[final_y_test[:, 1] == 1]\n",
    "final_fraud_y_test_prediction = final_y_test_prediction[final_y_test[:, 1] == 1]\n",
    "final_fraud_accuracy = calculate_accuracy(final_fraud_y_test, final_fraud_y_test_prediction)\n",
    "print('Final fraud specific accuracy: {0:.2f}%'.format(final_fraud_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
