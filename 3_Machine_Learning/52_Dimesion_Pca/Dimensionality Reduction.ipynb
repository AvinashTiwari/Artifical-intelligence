{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)\n",
    "  * Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space.\n",
    "  * [Wikipedia](https://en.wikipedia.org/wiki/Principal_component_analysis)\n",
    "  * Statistical procedure that utilise [orthogonal transformation](https://en.wikipedia.org/wiki/Orthogonal_transformation) technology\n",
    "  * Convert possible correlated features (predictors) into linearly uncorrelated features (predictors) called **principal components**\n",
    "  * \\# of principal components <= number of features (predictors)\n",
    "  * First principal component explains the largest possible variance\n",
    "  * Each subsequent component has the highest variance subject to the restriction that it must be orthogonal to the preceding components. \n",
    "  * A collection of the components are called vectors.\n",
    "  * Sensitive to scaling\n",
    "  * [Sebastian Raschka](http://sebastianraschka.com/Articles/2014_python_lda.html): Component axes that maximise the variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear Discriminant Analysis (LDA) \n",
    "  * [Wikipedia](https://en.wikipedia.org/wiki/Linear_discriminant_analysis)\n",
    "  * [Sebastian Raschka](http://sebastianraschka.com/Articles/2014_python_lda.html)\n",
    "  * Most commonly used as dimensionality reduction technique in the pre-processing step for pattern-classification and machine learning applications. \n",
    "  * Goal is to project a dataset onto a lower-dimensional space with good class-separability in order avoid overfitting (“curse of dimensionality”) and also reduce computational costs.\n",
    "  * Locate the 'boundaries' around clusters of classes.  \n",
    "  * Projects data points on a line\n",
    "  * A centroid will be allocated to each cluster or have a centroid nearby\n",
    "  * [Sebastian Raschka](http://sebastianraschka.com/Articles/2014_python_lda.html): Maximising the component axes for class-separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Dimensionality Reduction Techniques\n",
    "\n",
    "* [Multidimensional Scaling (MDS) ](http://scikit-learn.org/stable/modules/manifold.html#multi-dimensional-scaling-mds)\n",
    "  * Seeks a low-dimensional representation of the data in which the distances respect well the distances in the original high-dimensional space.\n",
    "\n",
    "\n",
    "* [Isomap (Isometric Mapping)](http://scikit-learn.org/stable/modules/manifold.html#isomap)\n",
    "\n",
    "  * Seeks a lower-dimensional embedding which maintains geodesic distances between all points.\n",
    "\n",
    "\n",
    "* [t-distributed Stochastic Neighbor Embedding (t-SNE)](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding)\n",
    "\n",
    "  * Nonlinear dimensionality reduction technique that is particularly well-suited for embedding high-dimensional data into a space of two or three dimensions, which can then be visualized in a scatter plot. \n",
    "  * Models each high-dimensional object by a two- or three-dimensional point in such a way that similar objects are modeled by nearby points and dissimilar objects are modeled by distant points. dimensional space (e.g., to visualize the MNIST images in 2D).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Gentle introduction to Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Algebra revision:\n",
    "\n",
    "$$A=\\begin{bmatrix} 1. & 2. \\\\ 10. & 20. \\end{bmatrix}$$\n",
    "\n",
    "$$B=\\begin{bmatrix} 1. & 2. \\\\ 100. & 200. \\end{bmatrix}$$\n",
    "\n",
    "\\begin{align}\n",
    "A \\times B & = \\begin{bmatrix} 1. & 2. \\\\ 10. & 20. \\end{bmatrix} \\times \\begin{bmatrix} 1. & 2. \\\\ 100. & 200. \\end{bmatrix} \\\\\n",
    "& = \\begin{bmatrix} 201. & 402. \\\\ 2010. & 4020. \\end{bmatrix} \\\\\n",
    "\\end{align}\n",
    "\n",
    "By parts:\n",
    "$$A \\times B = \\begin{bmatrix} 1. \\times 1. + 2.  \\times 100. &  1. \\times 2. + 2. \\times 200. \\\\ \n",
    "10. \\times 1. + 20. \\times 100. & 10. \\times 2. + 20. \\times 200. \\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = [[1., 2.], [10., 20.]]\n",
    "B = [[1., 2.], [100., 200.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 2.0], [10.0, 20.0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 2.0], [100.0, 200.0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  201.,   402.],\n",
       "       [ 2010.,  4020.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
