{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from time import time\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold,StratifiedKFold,ShuffleSplit,StratifiedShuffleSplit, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures,LabelEncoder,Imputer,RobustScaler, StandardScaler, MinMaxScaler,FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error,mean_squared_log_error,r2_score\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "from scipy import stats\n",
    "from scipy.stats import skew,randint\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import randint as sp_randint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature_importances(model,X):\n",
    "    important_features = pd.Series(data=rf_model.feature_importances_,index=X.columns)\n",
    "    important_features.sort_values(ascending=False,inplace=True)\n",
    "    print(important_features.head(50))\n",
    "    \n",
    "def get_cat_columns_by_type(df):\n",
    "    out = []\n",
    "    for colname,col_values in df.items():\n",
    "        if is_string_dtype(col_values):\n",
    "            out.append((colname,'string') )\n",
    "        elif not is_numeric_dtype(col_values):\n",
    "            out.append((colname,'categorical') )\n",
    "    return out       \n",
    "\n",
    "def get_numeric_columns(df):\n",
    "    out = []\n",
    "    for colname,col_values in df.items():\n",
    "        if is_numeric_dtype(col_values):\n",
    "            out.append(colname)\n",
    "    return out       \n",
    "    \n",
    "def get_missing_values_percentage(df):\n",
    "    missing_values_counts_list = df.isnull().sum()\n",
    "    total_values = np.product(df.shape)\n",
    "    total_missing = missing_values_counts_list.sum()\n",
    "    # percent of data that is missing\n",
    "    return (total_missing/total_values) * 100\n",
    "\n",
    "\n",
    "def convert_to_str_type(df_in,columns,inplace=False):\n",
    "    if(inplace):\n",
    "        df = df_in\n",
    "    else:\n",
    "        df = df_in.copy()\n",
    "        \n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "    return df\n",
    "\n",
    "def extract_and_drop_target_column(df_in, y_name, inplace=False):\n",
    "    if(inplace):\n",
    "        df = df_in\n",
    "    else:\n",
    "        df = df_in.copy()\n",
    "    if not is_numeric_dtype(df[y_name]):\n",
    "        df[y_name] = df[y_name].cat.codes\n",
    "        y = df[y_name].values\n",
    "    else:\n",
    "        y = df[y_name].copy()\n",
    "    df.drop([y_name], axis=1, inplace=True)\n",
    "    return (df,y)\n",
    "\n",
    "def get_cat_and_numerical_cols(df):\n",
    "    cat_cols = get_cat_columns_by_type(df)\n",
    "    cat_cols = [cat_cols[i][0] for i in range(len(cat_cols))]\n",
    "    num_cols = [col for col in df.columns if col not in cat_cols]\n",
    "    return cat_cols,num_cols\n",
    "\n",
    "    \n",
    "def clean_df(df,pipelines):\n",
    "    cat_cols, num_cols = get_cat_and_numerical_cols(df)\n",
    "    dfs = []\n",
    "    if len(num_cols):\n",
    "        df1 = df[num_cols]\n",
    "        print(df1.shape)\n",
    "        pipelines['pipe_df_missing_num'].fit(df1)\n",
    "        data1 = pipelines['pipe_df_missing_num'].transform(df1)\n",
    "        df1 = pd.DataFrame(data1,columns=num_cols)\n",
    "        dfs.append(df1)\n",
    "    \n",
    "    if len(cat_cols):\n",
    "        df2 = df[cat_cols]\n",
    "        print(df2.shape)\n",
    "        pipelines['pipe_df_missing_cat'].fit(df2)\n",
    "        data2 = pipelines['pipe_df_missing_cat'].transform(df2)     \n",
    "        df2 = pd.DataFrame(data2,columns=cat_cols)\n",
    "        dfs.append(df2)\n",
    "        \n",
    "        \n",
    "    return pd.concat(dfs,axis=1)\n",
    "\n",
    "# adapted from https://github.com/fastai/fastai/blob/master/fastai/structured.py\n",
    "def process_date_column(df_in, colname, include_time=False, inplace=True, \n",
    "                        date_format=None):\n",
    "    if(inplace):\n",
    "        df = df_in\n",
    "    else:\n",
    "        df = df_in.copy()\n",
    "        \n",
    "    prefix_without_date = re.sub('[Dd]ate$', '', colname)\n",
    "    if(df[colname].dtype != 'datetime64[ns]'):\n",
    "        if date_format is not None:\n",
    "            df[colname] = pd.to_datetime(df[colname],format=date_format)\n",
    "        else:\n",
    "            df[colname] = pd.to_datetime(df[colname],infer_datetime_format=True)\n",
    "    columns = ['Year', 'Month', 'Week','Day',\n",
    "               'Dayofweek', 'Dayofyear',\n",
    "               'Is_month_end','Is_month_start',\n",
    "               'Is_quarter_end','Is_quarter_start',\n",
    "               'Is_year_end','Is_year_start']\n",
    "    if include_time:\n",
    "        columns = columns + ['Hour', 'Minute', 'Second']\n",
    "    for c in columns:\n",
    "        df[prefix_without_date + '_' + c] = getattr(df[colname].dt,c.lower())\n",
    "    df[prefix_without_date] = df[colname].astype(np.int64) // (10 ** 9)\n",
    "    df.drop(colname,axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "def handle_encoding(df,one_hot=False,ignore_columns=None):\n",
    "    lbl = LabelEncoder()\n",
    "    cat_cols,_ = get_cat_and_numerical_cols(df)\n",
    "    print('len of cat cols = {}'.format(len(cat_cols)))\n",
    "    for colname in cat_cols:\n",
    "        if ignore_columns is not None:\n",
    "            if colname in ignore_columns:\n",
    "                continue\n",
    "        #print(colname)\n",
    "        lbl.fit(list(df[colname].values)) \n",
    "        df[colname] = lbl.transform(list(df[colname].values))\n",
    "        \n",
    "    if one_hot:\n",
    "        return pd.get_dummies(df,columns=cat_cols,dummy_na=True)\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "\n",
    "def get_iqr_min_max(df,cols):\n",
    "    out = {}\n",
    "    for colname, col_values in df.items():\n",
    "        if colname not in cols:\n",
    "            continue\n",
    "        quartile75, quartile25 = np.percentile(col_values, [75 ,25])\n",
    "        ## Inter Quartile Range ##\n",
    "        IQR = quartile75 - quartile25\n",
    "        min_value = quartile25 - (IQR*1.5)\n",
    "        max_value = quartile75 + (IQR*1.5)\n",
    "        out[colname] = (min_value,max_value)\n",
    "    return out\n",
    "\n",
    "def remove_skew(df,threshold=0.75,lambda_in=0.15):\n",
    "    cat_cols, num_cols = get_cat_and_numerical_cols(df)\n",
    "    skewed_cols = df[num_cols].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "    skewness = pd.DataFrame({'Skew' :skewed_cols})\n",
    "    skewness_log = skewness[abs(skewness) > threshold]\n",
    "    skewness_other = skewness[abs(skewness) <= threshold]\n",
    "    skewed_features_log = skewness_log.index\n",
    "    skewed_features_other = skewness_other.index\n",
    "    lambda_ = 0.0\n",
    "    for feature in skewed_features_log:\n",
    "        df[feature] = boxcox1p(df[feature],lambda_)\n",
    "        lambda_ = lambda_in\n",
    "    for feature in skewed_features_other:\n",
    "        df[feature] = boxcox1p(df[feature],lambda_)\n",
    "    return df\n",
    "\n",
    "def bin_numerical_columns(df_in,cols,inplace=False):\n",
    "    if(inplace):\n",
    "        df = df_in\n",
    "    else:\n",
    "        df = df_in.copy()\n",
    "        \n",
    "    for col in cols.keys():\n",
    "        bins = cols[col]\n",
    "        buckets_ = np.linspace(bins[0],bins[1],bins[2])\n",
    "        df[col] = pd.cut(df[col],buckets_,include_lowest=True)\n",
    "    return df\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report_best_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_df2(df,id_col= None,df_test=None,test_id=None,\n",
    "                   new_features_func=None,\n",
    "                   date_col=None,\n",
    "                   convert_to_cat_cols=None,\n",
    "                   bin_columns_dict=None,\n",
    "                   remove_skewness=False,\n",
    "                   skew_threshold=0.75,\n",
    "                   boxcox_lambda=0.15\n",
    "                  ):\n",
    "    \n",
    "            \n",
    "    if id_col is not None:\n",
    "        combined.drop(id_col, axis=1,inplace=True)\n",
    "        if df_test is not None and test_id is not None:\n",
    "            test_id = df_test[id_col].copy()\n",
    "        else: test_id = None\n",
    "           \n",
    "   \n",
    "    if new_features_func is not None:\n",
    "        df = new_features_func(df)\n",
    "    \n",
    "    if date_col is not None:\n",
    "        process_date_column(df,colname=date_col)\n",
    "        \n",
    "    if convert_to_cat_cols is not None:\n",
    "        df = convert_to_str_type(df,convert_to_cat_cols,inplace=True)\n",
    "        \n",
    "    if bin_columns_dict is not None:\n",
    "        df = bin_numerical_columns(df,bin_columns_dict,inplace=True)\n",
    "    \n",
    "    return df,test_id\n",
    "\n",
    "def create_cleaning_pipelines(log_y=False,one_hot=False):\n",
    "    def log_of_y(y):\n",
    "        if log_y:\n",
    "            return np.log1p(y)\n",
    "        else: \n",
    "            return y\n",
    "        \n",
    "    pipeline_y = make_pipeline(FunctionTransformer(log_of_y))\n",
    "    pipeline_df_missing_num = make_pipeline(Imputer(strategy='median',axis=0))\n",
    "    pipeline_df_missing_cat = make_pipeline(Imputer(strategy='most_frequent',axis=0)\n",
    "                                            \n",
    "                                            )\n",
    "    \n",
    "    return {'pipe_y':pipeline_y,\n",
    "            'pipe_df_missing_num':pipeline_df_missing_num,\n",
    "            'pipe_df_missing_cat':pipeline_df_missing_cat\n",
    "           }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_features1(df):\n",
    "    return df\n",
    "def add_new_features2(df):\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/bulldozers/\"\n",
    "df_raw = pd.read_csv(f'{PATH}train.csv', low_memory=False,\n",
    "                     parse_dates=[\"saledate\"])\n",
    "df_test = pd.read_csv(f'{PATH}test.csv', low_memory=False,parse_dates=['saledate'])\n",
    "\n",
    "df_raw.sort_values('saledate',inplace=True)\n",
    "df_test.sort_values('saledate',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 401125 entries, 205615 to 400217\n",
      "Data columns (total 53 columns):\n",
      "SalesID                     401125 non-null int64\n",
      "SalePrice                   401125 non-null int64\n",
      "MachineID                   401125 non-null int64\n",
      "ModelID                     401125 non-null int64\n",
      "datasource                  401125 non-null int64\n",
      "auctioneerID                380989 non-null float64\n",
      "YearMade                    401125 non-null int64\n",
      "MachineHoursCurrentMeter    142765 non-null float64\n",
      "UsageBand                   69639 non-null object\n",
      "saledate                    401125 non-null datetime64[ns]\n",
      "fiModelDesc                 401125 non-null object\n",
      "fiBaseModel                 401125 non-null object\n",
      "fiSecondaryDesc             263934 non-null object\n",
      "fiModelSeries               56908 non-null object\n",
      "fiModelDescriptor           71919 non-null object\n",
      "ProductSize                 190350 non-null object\n",
      "fiProductClassDesc          401125 non-null object\n",
      "state                       401125 non-null object\n",
      "ProductGroup                401125 non-null object\n",
      "ProductGroupDesc            401125 non-null object\n",
      "Drive_System                104361 non-null object\n",
      "Enclosure                   400800 non-null object\n",
      "Forks                       192077 non-null object\n",
      "Pad_Type                    79134 non-null object\n",
      "Ride_Control                148606 non-null object\n",
      "Stick                       79134 non-null object\n",
      "Transmission                183230 non-null object\n",
      "Turbocharged                79134 non-null object\n",
      "Blade_Extension             25219 non-null object\n",
      "Blade_Width                 25219 non-null object\n",
      "Enclosure_Type              25219 non-null object\n",
      "Engine_Horsepower           25219 non-null object\n",
      "Hydraulics                  320570 non-null object\n",
      "Pushblock                   25219 non-null object\n",
      "Ripper                      104137 non-null object\n",
      "Scarifier                   25230 non-null object\n",
      "Tip_Control                 25219 non-null object\n",
      "Tire_Size                   94718 non-null object\n",
      "Coupler                     213952 non-null object\n",
      "Coupler_System              43458 non-null object\n",
      "Grouser_Tracks              43362 non-null object\n",
      "Hydraulics_Flow             43362 non-null object\n",
      "Track_Type                  99153 non-null object\n",
      "Undercarriage_Pad_Width     99872 non-null object\n",
      "Stick_Length                99218 non-null object\n",
      "Thumb                       99288 non-null object\n",
      "Pattern_Changer             99218 non-null object\n",
      "Grouser_Type                99153 non-null object\n",
      "Backhoe_Mounting            78672 non-null object\n",
      "Blade_Type                  79833 non-null object\n",
      "Travel_Controls             79834 non-null object\n",
      "Differential_Type           69411 non-null object\n",
      "Steering_Controls           69369 non-null object\n",
      "dtypes: datetime64[ns](1), float64(2), int64(6), object(44)\n",
      "memory usage: 165.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Medium    33985\n",
       "Low       23620\n",
       "High      12034\n",
       "Name: UsageBand, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['UsageBand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "df,y = extract_and_drop_target_column(df,'SalePrice',inplace=True)\n",
    "\n",
    "n_train = df.shape[0]\n",
    "n_test = df_test.shape[0]\n",
    "    \n",
    "pipelines = create_cleaning_pipelines(log_y=True)\n",
    "\n",
    "combined = pd.concat((df, df_test)).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of cat cols = 50\n",
      "combined shape = (413582, 63)\n",
      "(413582, 63)\n",
      "0.0\n",
      "(401125, 1)\n",
      "0.0\n",
      "           0\n",
      "0   9.159152\n",
      "1  10.085851\n",
      "2  10.463132\n",
      "3   9.852247\n",
      "4   9.546884\n",
      "(401125,)\n"
     ]
    }
   ],
   "source": [
    "combined,test_id = preprocess_df2(combined,id_col='SalesID',\n",
    "                                    df_test=df_test,test_id='SalesID',\n",
    "                                    convert_to_cat_cols=['sale_Year', \n",
    "                                                         'sale_Month',\n",
    "                                                         'sale_Week',\n",
    "                                                         'sale_Day',\n",
    "                                                         'sale_Dayofweek',\n",
    "                                                         'sale_Dayofyear',\n",
    "                                                         'UsageBand'],\n",
    "                                    date_col='saledate'\n",
    "                                    \n",
    "                                   )\n",
    "\n",
    "combined = handle_encoding(combined,one_hot=False,ignore_columns=[\n",
    "                                                         'sale_Is_month_end',\n",
    "                                                         'sale_Is_month_start',\n",
    "                                                         'sale_Is_quarter_end',\n",
    "                                                         'sale_Is_quarter_start',\n",
    "                                                         'sale_Is_year_end',\n",
    "                                                         'sale_Is_year_start'\n",
    "                                                          ])\n",
    "print('combined shape = {}'.format(combined.shape) )\n",
    "combined = clean_df(combined,pipelines)\n",
    "\n",
    "combined = remove_skew(combined,threshold=0.75,lambda_in=0.15)\n",
    "print(get_missing_values_percentage(combined))\n",
    "\n",
    "y = clean_df(pd.DataFrame(y),pipelines)\n",
    "y = pipelines['pipe_y'].fit_transform(y)\n",
    "y = pd.DataFrame(y)\n",
    "print(get_missing_values_percentage(y))\n",
    "print(y.head())\n",
    "y = y.values.ravel()\n",
    "print(y.shape)\n",
    "df = combined[:n_train]\n",
    "df_test = combined[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((401125, 53), (401125, 63), (12457, 63))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.shape,df.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.000000\n",
       "1    0.571575\n",
       "2    0.571575\n",
       "3    0.571575\n",
       "4    0.571575\n",
       "Name: sale_Is_month_end, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sale_Is_month_end'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000916    331486\n",
       "0.834066     33985\n",
       "0.571575     23620\n",
       "0.000000     12034\n",
       "Name: UsageBand, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['UsageBand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MachineID</th>\n",
       "      <th>ModelID</th>\n",
       "      <th>datasource</th>\n",
       "      <th>auctioneerID</th>\n",
       "      <th>YearMade</th>\n",
       "      <th>MachineHoursCurrentMeter</th>\n",
       "      <th>UsageBand</th>\n",
       "      <th>fiModelDesc</th>\n",
       "      <th>fiBaseModel</th>\n",
       "      <th>fiSecondaryDesc</th>\n",
       "      <th>...</th>\n",
       "      <th>sale_Day</th>\n",
       "      <th>sale_Dayofweek</th>\n",
       "      <th>sale_Dayofyear</th>\n",
       "      <th>sale_Is_month_end</th>\n",
       "      <th>sale_Is_month_start</th>\n",
       "      <th>sale_Is_quarter_end</th>\n",
       "      <th>sale_Is_quarter_start</th>\n",
       "      <th>sale_Is_year_end</th>\n",
       "      <th>sale_Is_year_start</th>\n",
       "      <th>sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999089</td>\n",
       "      <td>3157</td>\n",
       "      <td>121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>521D</td>\n",
       "      <td>521</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>320</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1163635200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117657</td>\n",
       "      <td>77</td>\n",
       "      <td>121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996</td>\n",
       "      <td>4640.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>950FII</td>\n",
       "      <td>950</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>86</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1080259200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>434808</td>\n",
       "      <td>7009</td>\n",
       "      <td>121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>2838.0</td>\n",
       "      <td>High</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1077753600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1026470</td>\n",
       "      <td>332</td>\n",
       "      <td>121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>3486.0</td>\n",
       "      <td>High</td>\n",
       "      <td>PC120-6E</td>\n",
       "      <td>PC120</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>139</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1305763200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1057373</td>\n",
       "      <td>17311</td>\n",
       "      <td>121</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>722.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>S175</td>\n",
       "      <td>S175</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>204</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1248307200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MachineID  ModelID  datasource  auctioneerID  YearMade  \\\n",
       "0     999089     3157         121           3.0      2004   \n",
       "1     117657       77         121           3.0      1996   \n",
       "2     434808     7009         121           3.0      2001   \n",
       "3    1026470      332         121           3.0      2001   \n",
       "4    1057373    17311         121           3.0      2007   \n",
       "\n",
       "   MachineHoursCurrentMeter UsageBand fiModelDesc fiBaseModel fiSecondaryDesc  \\\n",
       "0                      68.0       Low        521D         521               D   \n",
       "1                    4640.0       Low      950FII         950               F   \n",
       "2                    2838.0      High         226         226            None   \n",
       "3                    3486.0      High    PC120-6E       PC120            None   \n",
       "4                     722.0    Medium        S175        S175            None   \n",
       "\n",
       "      ...     sale_Day sale_Dayofweek sale_Dayofyear sale_Is_month_end  \\\n",
       "0     ...           16              3            320             False   \n",
       "1     ...           26              4             86             False   \n",
       "2     ...           26              3             57             False   \n",
       "3     ...           19              3            139             False   \n",
       "4     ...           23              3            204             False   \n",
       "\n",
       "  sale_Is_month_start sale_Is_quarter_end sale_Is_quarter_start  \\\n",
       "0               False               False                 False   \n",
       "1               False               False                 False   \n",
       "2               False               False                 False   \n",
       "3               False               False                 False   \n",
       "4               False               False                 False   \n",
       "\n",
       "  sale_Is_year_end sale_Is_year_start        sale  \n",
       "0            False              False  1163635200  \n",
       "1            False              False  1080259200  \n",
       "2            False              False  1077753600  \n",
       "3            False              False  1305763200  \n",
       "4            False              False  1248307200  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline1 = make_pipeline(RobustScaler(),\n",
    "                                     StandardScaler(),\n",
    "                                     RandomForestRegressor())\n",
    "\n",
    "processing_pipeline2 = make_pipeline(RobustScaler(),\n",
    "                                     StandardScaler(),\n",
    "                                     GradientBoostingRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((401125, 63), (12457, 63), (401125,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape,df_test.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_split(df,y,n):\n",
    "    X_train =  df[:n].copy()\n",
    "    X_test = df[n:].copy()\n",
    "    y_train = y[:n].copy()\n",
    "    y_test  = y[n:].copy()\n",
    "    return X_train,X_test,y_train,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(389125, 63) (12000, 63) (389125,) (12000,)\n",
      "(377125, 63) (12000, 63) (377125,) (12000,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = simple_split(df,y,(df.shape[0] - test_size))\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "X_train,X_valid,y_train,y_valid = simple_split(X_train,y_train,\n",
    "                                               X_train.shape[0] - test_size)\n",
    "print(X_train.shape,X_valid.shape,y_train.shape,y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mse(m,X_train, X_valid, y_train, y_valid):\n",
    "    res = [mean_squared_error(y_train,m.predict(X_train)),\n",
    "                mean_squared_error(y_valid,m.predict(X_valid)),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    print('MSE Training set = {}, MSE Validation set = {}, score Training Set = {}, score on Validation Set = {}'.format(res[0],res[1],res[2], res[3]))\n",
    "    if hasattr(m, 'oob_score_'):\n",
    "          print('OOB Score = {}'.format(m.oob_score_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Training set = 0.008240246176169192, MSE Validation set = 0.06801319548831274, score Training Set = 0.9827875658877089, score on Validation Set = 0.864606918788001\n"
     ]
    }
   ],
   "source": [
    "pipe_model1 = processing_pipeline1.fit(X_train,y_train)\n",
    "print_mse(pipe_model1, X_train,X_valid,y_train,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Training set = 0.09793509560252386, MSE Validation set = 0.1016342400775218, score Training Set = 0.7954307014255928, score on Validation Set = 0.797677894385946\n"
     ]
    }
   ],
   "source": [
    "pipe_model2 = processing_pipeline2.fit(X_train,y_train)\n",
    "print_mse(pipe_model2, X_train,X_valid,y_train,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'randomforestregressor__n_estimators':[10,20,40,60],\n",
    "              \"randomforestregressor__max_features\": randint(10,64),\n",
    "              \"randomforestregressor__min_samples_split\": randint(2, 11),\n",
    "              \"randomforestregressor__min_samples_leaf\": randint(1, 11)\n",
    "         }\n",
    "\n",
    "start = time()\n",
    "randomSearch_p1 = RandomizedSearchCV(processing_pipeline1,\n",
    "                                     param_distributions=params,\n",
    "                                     n_iter=10,n_jobs=6,\n",
    "                                     scoring='neg_mean_squared_error'\n",
    "                                     ).fit(X_train,y_train)\n",
    "\n",
    "print('training took {} mins'.format((time() - start)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.132 (std: 0.062)\n",
      "Parameters: {'randomforestregressor__max_features': 40, 'randomforestregressor__min_samples_leaf': 2, 'randomforestregressor__min_samples_split': 4, 'randomforestregressor__n_estimators': 60}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.133 (std: 0.061)\n",
      "Parameters: {'randomforestregressor__max_features': 21, 'randomforestregressor__min_samples_leaf': 3, 'randomforestregressor__min_samples_split': 5, 'randomforestregressor__n_estimators': 40}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.133 (std: 0.060)\n",
      "Parameters: {'randomforestregressor__max_features': 26, 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 3, 'randomforestregressor__n_estimators': 60}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_best_scores(randomSearch_p1.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline_rf = make_pipeline(RobustScaler(),\n",
    "                                     StandardScaler(),\n",
    "                                     RandomForestRegressor(n_estimators=60,\n",
    "                                                          max_features=40,\n",
    "                                                          min_samples_leaf=2,\n",
    "                                                          min_samples_split=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Training set = 0.009840897453613554, MSE Validation set = 0.056392939526914904, score Training Set = 0.9794440851153209, score on Validation Set = 0.8877392278611147\n"
     ]
    }
   ],
   "source": [
    "pipe_model_rf = processing_pipeline_rf.fit(X_train,y_train)\n",
    "print_mse(pipe_model_rf, X_train,X_valid,y_train,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_model_rank1_bulldozers.pkl']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe_model_rf,'rf_model_rank1_bulldozers.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
