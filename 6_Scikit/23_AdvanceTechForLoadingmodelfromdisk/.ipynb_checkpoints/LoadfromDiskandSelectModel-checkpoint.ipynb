{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from time import time\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold,StratifiedKFold,ShuffleSplit,StratifiedShuffleSplit, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import RFE,SelectPercentile,f_regression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score, make_scorer\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "from scipy import stats\n",
    "from scipy.stats import skew,randint\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import randint as sp_randint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature_importances(model,X):\n",
    "    important_features = pd.Series(data=rf_model.feature_importances_,index=X.columns)\n",
    "    important_features.sort_values(ascending=False,inplace=True)\n",
    "    print(important_features.head(50))\n",
    "    \n",
    "def get_cat_columns_by_type(df):\n",
    "    out = []\n",
    "    for colname,col_values in df.items():\n",
    "        if is_string_dtype(col_values):\n",
    "            out.append((colname,'string') )\n",
    "        elif not is_numeric_dtype(col_values):\n",
    "            out.append((colname,'categorical') )\n",
    "    return out       \n",
    "\n",
    "def get_numeric_columns(df):\n",
    "    out = []\n",
    "    for colname,col_values in df.items():\n",
    "        if is_numeric_dtype(col_values):\n",
    "            out.append(colname)\n",
    "    return out       \n",
    "    \n",
    "def get_missing_values_percentage(df):\n",
    "    missing_values_counts_list = df.isnull().sum()\n",
    "    total_values = np.product(df.shape)\n",
    "    total_missing = missing_values_counts_list.sum()\n",
    "    # percent of data that is missing\n",
    "    return (total_missing/total_values) * 100\n",
    "\n",
    "def get_missing_columns(df1,df2):\n",
    "    missing1 = []\n",
    "    missing2 = []\n",
    "    for colname in df1.columns:\n",
    "        if colname not in df2.columns:\n",
    "            missing2.append(colname)\n",
    "    for colname in df2.columns:\n",
    "        if colname not in df1.columns:\n",
    "            missing1.append(colname)        \n",
    "    return (missing1,missing2)\n",
    "\n",
    "\n",
    "def convert_to_str_type(df_in,columns,inplace=False):\n",
    "    if(inplace):\n",
    "        df = df_in\n",
    "    else:\n",
    "        df = df_in.copy()\n",
    "        \n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "    return df\n",
    "\n",
    "    \n",
    "def handle_missing_values(df_in,cat_cols=[], num_cols=[],na_dict=None,add_nan_col=True,inplace=False):\n",
    "    if(inplace):\n",
    "        df = df_in\n",
    "    else:\n",
    "        df = df_in.copy()\n",
    " \n",
    "    if na_dict is None:\n",
    "        na_dict = {}\n",
    "\n",
    "    for colname, col_values in df.items():   \n",
    "        if colname not in num_cols:\n",
    "            continue\n",
    "        if pd.isnull(col_values).sum():\n",
    "            df[colname+'_na'] = pd.isnull(col_values)\n",
    "            filler = na_dict[colname] if colname in na_dict else col_values.median()\n",
    "            df[colname] = col_values.fillna(filler)\n",
    "            na_dict[colname] = filler\n",
    "    for colname in cat_cols:\n",
    "        if colname not in df.columns:\n",
    "            continue\n",
    "        df[colname].fillna(df[colname].mode()[0], inplace=True)\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(df[colname].values)) \n",
    "        df[colname] = lbl.transform(list(df[colname].values))\n",
    "    \n",
    "    return (df,na_dict)\n",
    "\n",
    "\n",
    "\n",
    "def scale_num_cols(df_in, mapper, inplace=False):\n",
    "    if(inplace):\n",
    "        df = df_in\n",
    "    else:\n",
    "        df = df_in.copy()\n",
    "        \n",
    "    if mapper is None:\n",
    "        map_f = [([c],StandardScaler()) for c in df.columns if is_numeric_dtype(df[c])]\n",
    "        mapper = DataFrameMapper(map_f).fit(df)\n",
    "    df[mapper.transformed_names_] = mapper.transform(df)\n",
    "    return (df,mapper)\n",
    "\n",
    "\n",
    "\n",
    "def extract_and_drop_target_column(df_in, y_name, inplace=False):\n",
    "    if(inplace):\n",
    "        df = df_in\n",
    "    else:\n",
    "        df = df_in.copy()\n",
    "    if not is_numeric_dtype(df[y_name]):\n",
    "        df[y_name] = df[y_name].cat.codes\n",
    "        y = df[y_name].values\n",
    "    else:\n",
    "        y = df[y_name]\n",
    "    df.drop([y_name], axis=1, inplace=True)\n",
    "    return (df,y)\n",
    "\n",
    "def print_mse(m,X_train, X_valid, y_train, y_valid):\n",
    "    res = [mean_squared_error(y_train,m.predict(X_train)),\n",
    "                mean_squared_error(y_valid,m.predict(X_valid)),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    print('MSE Training set = {}, MSE Validation set = {}, score Training Set = {}, score on Validation Set = {}'.format(res[0],res[1],res[2], res[3]))\n",
    "    if hasattr(m, 'oob_score_'):\n",
    "          print('OOB Score = {}'.format(m.oob_score_))      \n",
    "\n",
    "def get_iqr_min_max(df,cols):\n",
    "    out = {}\n",
    "    for colname, col_values in df.items():\n",
    "        if colname not in cols:\n",
    "            continue\n",
    "        quartile75, quartile25 = np.percentile(col_values, [75 ,25])\n",
    "        ## Inter Quartile Range ##\n",
    "        IQR = quartile75 - quartile25\n",
    "        min_value = quartile25 - (IQR*1.5)\n",
    "        max_value = quartile75 + (IQR*1.5)\n",
    "        out[colname] = (min_value,max_value)\n",
    "    return out\n",
    "\n",
    "\n",
    "def bin_numerical_columns(df_in,cols,inplace=False):\n",
    "    if(inplace):\n",
    "        df = df_in\n",
    "    else:\n",
    "        df = df_in.copy()\n",
    "        \n",
    "    for col in cols.keys():\n",
    "        bins = cols[col]\n",
    "        buckets_ = np.linspace(bins[0],bins[1],bins[2])\n",
    "        df[col] = pd.cut(df[col],buckets_,include_lowest=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df_train,df_test=None,\n",
    "                  log_y=False,\n",
    "                  id_col= None,test_id=None,\n",
    "                  target_col=None,\n",
    "                  convert_to_cat_cols=None,\n",
    "                  remove_skewness=False,\n",
    "                  skew_threshold=0.75,\n",
    "                  boxcox_lambda=0.15,\n",
    "                  scale_mapper=None,\n",
    "                  bin_columns_dict=None,\n",
    "                  new_features_func=None):\n",
    "    \n",
    "    if target_col is not None:\n",
    "        df,y = extract_and_drop_target_column(df_train,target_col,inplace=True)\n",
    "        print(y.head())\n",
    "        if log_y:\n",
    "            y = np.log1p(y)\n",
    "            \n",
    "    else:\n",
    "        y = None\n",
    "        \n",
    "        \n",
    "    combined = pd.concat((df, df_test)).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    if id_col is not None:\n",
    "        combined.drop(id_col, axis=1,inplace=True)\n",
    "        if test_id is not None:\n",
    "            test_id = df_test[id_col].copy()\n",
    "        else: test_id = None\n",
    "   \n",
    "    if new_features_func is not None:\n",
    "        combined = new_features_func(combined)\n",
    "    \n",
    "    \n",
    "    if convert_to_cat_cols is not None:\n",
    "        combined = convert_to_str_type(combined,convert_to_cat_cols,inplace=True)\n",
    "    \n",
    "        \n",
    "    if bin_columns_dict is not None:\n",
    "        combined = bin_numerical_columns(combined,bin_columns_dict,inplace=True)\n",
    "    \n",
    "    \n",
    "    cat_cols = get_cat_columns_by_type(combined)\n",
    "    cat_cols = [cat_cols[i][0] for i in range(len(cat_cols))]\n",
    "    num_cols = [col for col in combined.columns if col not in cat_cols]\n",
    "    \n",
    "    combined = pd.get_dummies(combined,columns=cat_cols, dummy_na=True)\n",
    "    \n",
    "    n_train = df.shape[0]\n",
    "    n_test = df_test.shape[0]\n",
    "      \n",
    "    \n",
    "    combined,d = handle_missing_values(combined,cat_cols=cat_cols,\n",
    "                                       num_cols=num_cols,inplace=True)\n",
    "    \n",
    "    print(d)\n",
    "    if remove_skewness:\n",
    "        skewed_cols = combined[num_cols].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "        skewness = pd.DataFrame({'Skew' :skewed_cols})\n",
    "        skewness_log = skewness[abs(skewness) > skew_threshold]\n",
    "        skewness_other = skewness[abs(skewness) <= skew_threshold]\n",
    "        skewed_features_log = skewness_log.index\n",
    "        skewed_features_other = skewness_other.index\n",
    "        lambda_ = 0.0\n",
    "        for feature in skewed_features_log:\n",
    "            combined[feature] = boxcox1p(combined[feature],lambda_)\n",
    "        lambda_ = boxcox_lambda\n",
    "        for feature in skewed_features_other:\n",
    "            combined[feature] = boxcox1p(combined[feature],lambda_)\n",
    "    \n",
    "    if scale_mapper is not None:\n",
    "        map_f = [([c],scale_mapper) for c in num_cols]\n",
    "        mapper = DataFrameMapper(map_f).fit(combined)\n",
    "    else:\n",
    "        mapper = None\n",
    "        \n",
    "    combined,_ = scale_num_cols(combined,mapper,inplace=True) \n",
    "    \n",
    "    print(get_missing_values_percentage(combined))\n",
    "    \n",
    "    return combined,df,y,cat_cols,num_cols,test_id,n_train,n_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_features1(df):\n",
    "    df['DepsIncomeComined'] = df['NumberOfDependents'] * df['MonthlyIncome']\n",
    "    df['Times90DaysLateDebtRatio'] = df['NumberOfTimes90DaysLate'] * df['DebtRatio']\n",
    "    df['Times90DaysLateRevolving'] = df['NumberOfTimes90DaysLate'] * df['RevolvingUtilizationOfUnsecuredLines']\n",
    "    return df\n",
    "def add_new_features2(df):\n",
    "    df['DepsIncomeComined'] = df['NumberOfDependents'] * df['MonthlyIncome']\n",
    "    df['Times90DaysLateDebtRatio'] = df['NumberOfTimes90DaysLate'] * df['DebtRatio']\n",
    "    df['Times90DaysLateRevolving'] = df['NumberOfTimes90DaysLate'] * df['RevolvingUtilizationOfUnsecuredLines']\n",
    "    df['RevolvingUtilizationOfUnsecuredLines-2'] = df['RevolvingUtilizationOfUnsecuredLines'] ** 2\n",
    "    df['RevolvingUtilizationOfUnsecuredLines-3'] = df['RevolvingUtilizationOfUnsecuredLines'] ** 3\n",
    "    df['RevolvingUtilizationOfUnsecuredLines-sqrt'] = np.sqrt(df['RevolvingUtilizationOfUnsecuredLines'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: SeriousDlqin2yrs, dtype: int64\n",
      "{'MonthlyIncome': 5400.0, 'NumberOfDependents': 0.0, 'DepsIncomeComined': 0.0}\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((108000, 49), (27000, 49), (108000,), (27000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"data/give_me_credit/\"\n",
    "df_raw = pd.read_csv(f'{PATH}train.csv', low_memory=False)\n",
    "df_test = pd.read_csv(f'{PATH}test.csv', low_memory=False)\n",
    "columns = ['Id', 'SeriousDlqin2yrs','RevolvingUtilizationOfUnsecuredLines', 'age',\n",
    "                 'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome',\n",
    "                 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',\n",
    "                 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse',\n",
    "                 'NumberOfDependents']\n",
    "df_raw.columns= columns\n",
    "df_test.columns = columns\n",
    "df_test.drop(['SeriousDlqin2yrs'], axis=1, inplace=True)\n",
    "df = df_raw.copy()\n",
    "combined,df,y,cat_cols,num_cols,test_id,n_train,n_test = preprocess_df(\n",
    "                                       df_train=df,df_test=df_test,\n",
    "                                       target_col='SeriousDlqin2yrs',\n",
    "                                       id_col='Id',test_id='Id',\n",
    "                                       convert_to_cat_cols=[\n",
    "                                       'NumberOfTime30-59DaysPastDueNotWorse',\n",
    "                                       'NumberOfTime60-89DaysPastDueNotWorse'\n",
    "                                       ],\n",
    "                                       new_features_func=add_new_features2,\n",
    "                                       remove_skewness=True,\n",
    "                                       skew_threshold=0.75,\n",
    "                                       boxcox_lambda=0.2,\n",
    "                                       scale_mapper=RobustScaler()\n",
    "                                       )\n",
    "\n",
    "df = combined[:n_train]\n",
    "df_test = combined[n_train:]\n",
    "stratify_col = y\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(df,y,test_size=0.10,\n",
    "                                  stratify=y,shuffle = True,random_state=20)\n",
    "\n",
    "stratify_X_train = stratify_col[:X_train.shape[0]].copy()\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape, stratify_X_train.shape\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X_train,y_train,test_size=0.2,\n",
    "                                  stratify=stratify_X_train,shuffle = True,random_state=20)\n",
    "X_train.shape,X_valid.shape,y_train.shape,y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_randomSearch = joblib.load('randomSearch_rf_credit.pkl')\n",
    "rf_model_rank1 =  joblib.load('rf_model_credit_rank1.pkl')\n",
    "rf_model_rank2 =  joblib.load('rf_model_credit_rank2.pkl')\n",
    "rf_model_rank3 =  joblib.load('rf_model_credit_rank3.pkl')\n",
    "\n",
    "gb_randomSearch = joblib.load('randomSearch_gb_credit.pkl')\n",
    "gb_model_rank1 =  joblib.load('gb_model_credit_rank1.pkl')\n",
    "gb_model_rank2 =  joblib.load('gb_model_credit_rank2.pkl')\n",
    "gb_model_rank3 =  joblib.load('gb_model_credit_rank3.pkl')\n",
    "gb_rfe_model =    joblib.load('rfe_model_credit.pkl')\n",
    "\n",
    "knn_randomSearch = joblib.load('randomSearch_knn.pkl')\n",
    "knn_model_rank1 =  joblib.load('knn_model_rank1.pkl')\n",
    "knn_model_rank2 =  joblib.load('knn_model_rank2.pkl')\n",
    "knn_model_rank3 =  joblib.load('knn_model_rank3.pkl')\n",
    "\n",
    "nb_model = joblib.load('nb_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_X_valid = {}\n",
    "preds_X_valid['rf_randomSearch'] = rf_randomSearch.predict_proba(X_valid)[:, 1]\n",
    "preds_X_valid['rf_model_rank1'] =  rf_model_rank1.predict_proba(X_valid)[:, 1]\n",
    "preds_X_valid['rf_model_rank2'] =  rf_model_rank2.predict_proba(X_valid)[:, 1]\n",
    "preds_X_valid['rf_model_rank3'] =  rf_model_rank3.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "preds_X_valid['gb_randomSearch'] =    gb_randomSearch.predict_proba(X_valid)[:, 1]\n",
    "preds_X_valid['gb_model_rank1'] =     gb_model_rank1.predict_proba(X_valid)[:, 1]\n",
    "preds_X_valid['gb_model_rank2'] =     gb_model_rank2.predict_proba(X_valid)[:, 1]\n",
    "preds_X_valid['gb_model_rank3'] =     gb_model_rank3.predict_proba(X_valid)[:, 1]\n",
    "preds_X_valid['gb_rfe_model'] =       gb_rfe_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "preds_X_valid['knn_randomSearch'] = knn_randomSearch.predict_proba(X_valid)[:, 1]\n",
    "preds_X_valid['knn_model_rank1'] =  knn_model_rank1.predict_proba(X_valid)[:, 1]\n",
    "preds_X_valid['knn_model_rank2'] =  knn_model_rank2.predict_proba(X_valid)[:, 1]\n",
    "preds_X_valid['knn_model_rank3'] =  knn_model_rank3.predict_proba(X_valid)[:, 1]\n",
    "preds_X_valid['nb_model'] =         nb_model.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_randomSearch</th>\n",
       "      <th>rf_model_rank1</th>\n",
       "      <th>rf_model_rank2</th>\n",
       "      <th>rf_model_rank3</th>\n",
       "      <th>gb_randomSearch</th>\n",
       "      <th>gb_model_rank1</th>\n",
       "      <th>gb_model_rank2</th>\n",
       "      <th>gb_model_rank3</th>\n",
       "      <th>gb_rfe_model</th>\n",
       "      <th>knn_randomSearch</th>\n",
       "      <th>knn_model_rank1</th>\n",
       "      <th>knn_model_rank2</th>\n",
       "      <th>knn_model_rank3</th>\n",
       "      <th>nb_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>0.012074</td>\n",
       "      <td>0.012709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.890340e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.010650</td>\n",
       "      <td>0.010203</td>\n",
       "      <td>0.010452</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.010664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.179547e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007336</td>\n",
       "      <td>0.008710</td>\n",
       "      <td>0.006219</td>\n",
       "      <td>0.012567</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.012847</td>\n",
       "      <td>0.013925</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>0.013422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.262024e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043558</td>\n",
       "      <td>0.045979</td>\n",
       "      <td>0.049184</td>\n",
       "      <td>0.049593</td>\n",
       "      <td>0.018668</td>\n",
       "      <td>0.016664</td>\n",
       "      <td>0.016677</td>\n",
       "      <td>0.016385</td>\n",
       "      <td>0.017056</td>\n",
       "      <td>0.047081</td>\n",
       "      <td>0.047081</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.044225</td>\n",
       "      <td>8.384361e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027979</td>\n",
       "      <td>0.031671</td>\n",
       "      <td>0.034410</td>\n",
       "      <td>0.028253</td>\n",
       "      <td>0.026992</td>\n",
       "      <td>0.027272</td>\n",
       "      <td>0.026003</td>\n",
       "      <td>0.026755</td>\n",
       "      <td>0.025542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>4.869339e-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rf_randomSearch  rf_model_rank1  rf_model_rank2  rf_model_rank3  \\\n",
       "0         0.000273        0.000327        0.000279        0.000588   \n",
       "1         0.001629        0.002634        0.003260        0.001594   \n",
       "2         0.007336        0.008710        0.006219        0.012567   \n",
       "3         0.043558        0.045979        0.049184        0.049593   \n",
       "4         0.027979        0.031671        0.034410        0.028253   \n",
       "\n",
       "   gb_randomSearch  gb_model_rank1  gb_model_rank2  gb_model_rank3  \\\n",
       "0         0.012073        0.011500        0.010581        0.012074   \n",
       "1         0.010650        0.010203        0.010452        0.010139   \n",
       "2         0.013377        0.012847        0.013925        0.013617   \n",
       "3         0.018668        0.016664        0.016677        0.016385   \n",
       "4         0.026992        0.027272        0.026003        0.026755   \n",
       "\n",
       "   gb_rfe_model  knn_randomSearch  knn_model_rank1  knn_model_rank2  \\\n",
       "0      0.012709          0.000000         0.000000             0.00   \n",
       "1      0.010664          0.000000         0.000000             0.00   \n",
       "2      0.013422          0.000000         0.000000             0.00   \n",
       "3      0.017056          0.047081         0.047081             0.02   \n",
       "4      0.025542          0.000000         0.000000             0.00   \n",
       "\n",
       "   knn_model_rank3      nb_model  \n",
       "0         0.000000  1.890340e-27  \n",
       "1         0.000000  5.179547e-28  \n",
       "2         0.000000  1.262024e-26  \n",
       "3         0.044225  8.384361e-28  \n",
       "4         0.005870  4.869339e-26  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df_valid = pd.DataFrame(preds_X_valid,columns = preds_X_valid.keys())\n",
    "preds_df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27000, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_X_test = {}\n",
    "preds_X_test['rf_randomSearch'] = rf_randomSearch.predict_proba(X_test)[:, 1]\n",
    "preds_X_test['rf_model_rank1'] =  rf_model_rank1.predict_proba(X_test)[:, 1]\n",
    "preds_X_test['rf_model_rank2'] =  rf_model_rank2.predict_proba(X_test)[:, 1]\n",
    "preds_X_test['rf_model_rank3'] =  rf_model_rank3.predict_proba(X_test)[:, 1]\n",
    "\n",
    "preds_X_test['gb_randomSearch'] =    gb_randomSearch.predict_proba(X_test)[:, 1]\n",
    "preds_X_test['gb_model_rank1'] =     gb_model_rank1.predict_proba(X_test)[:, 1]\n",
    "preds_X_test['gb_model_rank2'] =     gb_model_rank2.predict_proba(X_test)[:, 1]\n",
    "preds_X_test['gb_model_rank3'] =     gb_model_rank3.predict_proba(X_test)[:, 1]\n",
    "preds_X_test['gb_rfe_model'] =       gb_rfe_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "preds_X_test['knn_randomSearch'] = knn_randomSearch.predict_proba(X_test)[:, 1]\n",
    "preds_X_test['knn_model_rank1'] =  knn_model_rank1.predict_proba(X_test)[:, 1]\n",
    "preds_X_test['knn_model_rank2'] =  knn_model_rank2.predict_proba(X_test)[:, 1]\n",
    "preds_X_test['knn_model_rank3'] =  knn_model_rank3.predict_proba(X_test)[:, 1]\n",
    "preds_X_test['nb_model'] =         nb_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_randomSearch</th>\n",
       "      <th>rf_model_rank1</th>\n",
       "      <th>rf_model_rank2</th>\n",
       "      <th>rf_model_rank3</th>\n",
       "      <th>gb_randomSearch</th>\n",
       "      <th>gb_model_rank1</th>\n",
       "      <th>gb_model_rank2</th>\n",
       "      <th>gb_model_rank3</th>\n",
       "      <th>gb_rfe_model</th>\n",
       "      <th>knn_randomSearch</th>\n",
       "      <th>knn_model_rank1</th>\n",
       "      <th>knn_model_rank2</th>\n",
       "      <th>knn_model_rank3</th>\n",
       "      <th>nb_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055386</td>\n",
       "      <td>0.054240</td>\n",
       "      <td>0.049262</td>\n",
       "      <td>0.042250</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.060023</td>\n",
       "      <td>0.064902</td>\n",
       "      <td>0.059734</td>\n",
       "      <td>0.065045</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.026921</td>\n",
       "      <td>0.032</td>\n",
       "      <td>2.096060e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.006811</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.013629</td>\n",
       "      <td>0.013879</td>\n",
       "      <td>0.015832</td>\n",
       "      <td>0.013313</td>\n",
       "      <td>0.015855</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.011205</td>\n",
       "      <td>0.016</td>\n",
       "      <td>4.014908e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016616</td>\n",
       "      <td>0.016010</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.016280</td>\n",
       "      <td>0.020406</td>\n",
       "      <td>0.021168</td>\n",
       "      <td>0.019183</td>\n",
       "      <td>0.018661</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.040635</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.030428</td>\n",
       "      <td>0.032</td>\n",
       "      <td>1.626583e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102430</td>\n",
       "      <td>0.103847</td>\n",
       "      <td>0.117195</td>\n",
       "      <td>0.103854</td>\n",
       "      <td>0.083615</td>\n",
       "      <td>0.088272</td>\n",
       "      <td>0.091648</td>\n",
       "      <td>0.089743</td>\n",
       "      <td>0.090508</td>\n",
       "      <td>0.182027</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.113233</td>\n",
       "      <td>0.088</td>\n",
       "      <td>9.827210e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.072616</td>\n",
       "      <td>0.075211</td>\n",
       "      <td>0.072348</td>\n",
       "      <td>0.055465</td>\n",
       "      <td>0.084035</td>\n",
       "      <td>0.099241</td>\n",
       "      <td>0.083450</td>\n",
       "      <td>0.095657</td>\n",
       "      <td>0.096443</td>\n",
       "      <td>0.065331</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.090835</td>\n",
       "      <td>0.104</td>\n",
       "      <td>3.974356e-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rf_randomSearch  rf_model_rank1  rf_model_rank2  rf_model_rank3  \\\n",
       "0         0.055386        0.054240        0.049262        0.042250   \n",
       "1         0.005500        0.006811        0.003191        0.002228   \n",
       "2         0.016616        0.016010        0.020862        0.016280   \n",
       "3         0.102430        0.103847        0.117195        0.103854   \n",
       "4         0.072616        0.075211        0.072348        0.055465   \n",
       "\n",
       "   gb_randomSearch  gb_model_rank1  gb_model_rank2  gb_model_rank3  \\\n",
       "0         0.058333        0.060023        0.064902        0.059734   \n",
       "1         0.013629        0.013879        0.015832        0.013313   \n",
       "2         0.020406        0.021168        0.019183        0.018661   \n",
       "3         0.083615        0.088272        0.091648        0.089743   \n",
       "4         0.084035        0.099241        0.083450        0.095657   \n",
       "\n",
       "   gb_rfe_model  knn_randomSearch  knn_model_rank1  knn_model_rank2  \\\n",
       "0      0.065045          0.017384         0.033333         0.026921   \n",
       "1      0.015855          0.013576         0.013333         0.011205   \n",
       "2      0.017242          0.040635         0.033333         0.030428   \n",
       "3      0.090508          0.182027         0.080000         0.113233   \n",
       "4      0.096443          0.065331         0.093333         0.090835   \n",
       "\n",
       "   knn_model_rank3      nb_model  \n",
       "0            0.032  2.096060e-24  \n",
       "1            0.016  4.014908e-27  \n",
       "2            0.032  1.626583e-26  \n",
       "3            0.088  9.827210e-23  \n",
       "4            0.104  3.974356e-22  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df_test = pd.DataFrame(preds_X_test,columns = preds_X_test.keys())\n",
    "preds_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pipeline = make_pipeline(StandardScaler(),\n",
    "                              ElasticNet(warm_start=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'elasticnet__alpha':[0.001,0.01,0.1,1.],\n",
    "          'elasticnet__l1_ratio': [0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "          'elasticnet__max_iter':[1000,2000,5000,10000],\n",
    "          'elasticnet__selection':['cyclic','random']\n",
    "         }\n",
    "\n",
    "rs_meta_elastic = RandomizedSearchCV(meta_pipeline,param_distributions=params,\n",
    "                                          n_jobs=6, n_iter=20).fit(preds_df_valid,y_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'elasticnet__alpha':[0.001,0.01,0.1,1.],\n",
    "          'elasticnet__l1_ratio': [0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "          'elasticnet__max_iter':[1000,2000,5000,10000],\n",
    "          'elasticnet__selection':['cyclic','random']\n",
    "         }\n",
    "\n",
    "rs_meta_elastic = RandomizedSearchCV(meta_pipeline,param_distributions=params,\n",
    "                                          n_jobs=6, n_iter=20).fit(preds_df_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = {}\n",
    "preds_test['rf_randomSearch'] = rf_randomSearch.predict_proba(df_test)[:, 1]\n",
    "preds_test['rf_model_rank1'] =  rf_model_rank1.predict_proba(df_test)[:, 1]\n",
    "preds_test['rf_model_rank2'] =  rf_model_rank2.predict_proba(df_test)[:, 1]\n",
    "preds_test['rf_model_rank3'] =  rf_model_rank3.predict_proba(df_test)[:, 1]\n",
    "\n",
    "preds_test['gb_randomSearch'] =    gb_randomSearch.predict_proba(df_test)[:, 1]\n",
    "preds_test['gb_model_rank1'] =     gb_model_rank1.predict_proba(df_test)[:, 1]\n",
    "preds_test['gb_model_rank2'] =     gb_model_rank2.predict_proba(df_test)[:, 1]\n",
    "preds_test['gb_model_rank3'] =     gb_model_rank3.predict_proba(df_test)[:, 1]\n",
    "preds_test['gb_rfe_model'] =       gb_rfe_model.predict_proba(df_test)[:, 1]\n",
    "\n",
    "preds_test['knn_randomSearch'] = knn_randomSearch.predict_proba(df_test)[:, 1]\n",
    "preds_test['knn_model_rank1'] =  knn_model_rank1.predict_proba(df_test)[:, 1]\n",
    "preds_test['knn_model_rank2'] =  knn_model_rank2.predict_proba(df_test)[:, 1]\n",
    "preds_test['knn_model_rank3'] =  knn_model_rank3.predict_proba(df_test)[:, 1]\n",
    "preds_test['nb_model'] =         nb_model.predict_proba(df_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_df = pd.DataFrame(preds_test,columns = preds_test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_preds_test = rs_meta_elastic.predict(preds_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.064935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.049851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.015387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.057893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.107704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Probability\n",
       "0   1     0.064935\n",
       "1   2     0.049851\n",
       "2   3     0.015387\n",
       "3   4     0.057893\n",
       "4   5     0.107704"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df_submit = pd.DataFrame({'Id':test_id, 'Probability': pd.Series(meta_preds_test)},\n",
    "              columns=['Id', 'Probability'])\n",
    "meta_df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101498</th>\n",
       "      <td>101499</td>\n",
       "      <td>0.024168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101499</th>\n",
       "      <td>101500</td>\n",
       "      <td>0.346459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101500</th>\n",
       "      <td>101501</td>\n",
       "      <td>0.006604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101501</th>\n",
       "      <td>101502</td>\n",
       "      <td>0.079869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101502</th>\n",
       "      <td>101503</td>\n",
       "      <td>0.041600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  Probability\n",
       "101498  101499     0.024168\n",
       "101499  101500     0.346459\n",
       "101500  101501     0.006604\n",
       "101501  101502     0.079869\n",
       "101502  101503     0.041600"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df_submit.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
