{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/labeledTrainData.tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 318\n",
      "Every 10th stopword:\n",
      "['is', 'we', 'mostly', 'i', 'seem', 'may', 'least', 'five', 'amongst', 'find', 'fifty', 'moreover', 'whatever', 'or', 'namely', 'former', 'be', 'them', 'perhaps', 'in', 'too', 'sixty', 'whence', 'de', 'anyhow', 'first', 'else', 'those', 'give', 'and', 'throughout', 'latterly']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of stop words: {}\".format(len(ENGLISH_STOP_WORDS)))\n",
    "print(\"Every 10th stopword:\\n{}\".format(list(ENGLISH_STOP_WORDS)[::10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_split(data,y,length,split_mark=0.7):\n",
    "    if split_mark > 0. and split_mark < 1.0:\n",
    "        n = int(split_mark*length)\n",
    "    else:\n",
    "        n = int(split_mark)\n",
    "    X_train =  data[:n].copy()\n",
    "    X_test =   data[n:].copy()\n",
    "    y_train = y[:n].copy()\n",
    "    y_test  = y[n:].copy()\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=5, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500, 3) (7500, 3) (17500,) (7500,)\n"
     ]
    }
   ],
   "source": [
    "d_train,d_test,y_train,y_test = simple_split(data,data.sentiment,len(data))\n",
    "print(d_train.shape,d_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = d_train.review\n",
    "X_test = d_test.review\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X_train_vect, y_train, cv=5)\n",
    "print(\"Mean cross-validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.999\n",
      "Test set score: 0.871\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_vect, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train_vect, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_vect, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.89\n",
      "GridSearchCV took 2.878620119889577 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "pipe = make_pipeline(TfidfVectorizer(min_df=5, norm=None),\n",
    "LogisticRegression())\n",
    "param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(d_train.review, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print('GridSearchCV took {} minutes'.format((time() - start)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = grid.best_estimator_.named_steps[\"tfidfvectorizer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.transform(d_train.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 22990)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 22901)\t3.1953727427163816\n",
      "  (0, 22754)\t2.1251307485790303\n",
      "  (0, 22725)\t4.482154740974373\n",
      "  (0, 22665)\t8.824103152080845\n",
      "  (0, 22647)\t5.4360816627251864\n",
      "  (0, 22525)\t2.8686359473435417\n",
      "  (0, 22513)\t7.243652776519996\n",
      "  (0, 22510)\t6.473708987361189\n",
      "  (0, 22505)\t5.377464300512746\n",
      "  (0, 22464)\t6.574046362895457\n",
      "  (0, 22462)\t4.445654338754847\n",
      "  (0, 22453)\t6.039048352537808\n",
      "  (0, 22411)\t4.403113631564757\n",
      "  (0, 22307)\t2.8850603553763436\n",
      "  (0, 22303)\t7.074560329917086\n",
      "  (0, 22285)\t2.872787825999607\n",
      "  (0, 22239)\t4.077929558629529\n",
      "  (0, 22236)\t4.0378025946689515\n",
      "  (0, 22235)\t3.080642193606467\n",
      "  (0, 22100)\t5.682416965903773\n",
      "  (0, 21895)\t5.681053555643737\n",
      "  (0, 21812)\t4.354916341964563\n",
      "  (0, 21749)\t2.055445750299673\n",
      "  (0, 21625)\t4.602496810247816\n",
      "  (0, 21272)\t5.3450632836547545\n",
      "  :\t:\n",
      "  (17499, 10052)\t3.969843232833958\n",
      "  (17499, 9497)\t4.683221730226808\n",
      "  (17499, 9027)\t2.373632729936668\n",
      "  (17499, 8877)\t3.9131496132153023\n",
      "  (17499, 8833)\t2.7835083625821624\n",
      "  (17499, 8691)\t5.349478301863871\n",
      "  (17499, 8441)\t3.077899961540691\n",
      "  (17499, 8439)\t5.301953160001026\n",
      "  (17499, 8111)\t4.980053130238904\n",
      "  (17499, 7644)\t3.849341796887474\n",
      "  (17499, 7044)\t4.2391356734102725\n",
      "  (17499, 5403)\t3.858266000884483\n",
      "  (17499, 4716)\t2.439631731786739\n",
      "  (17499, 3971)\t13.839731398852198\n",
      "  (17499, 3496)\t2.5964378145020044\n",
      "  (17499, 3486)\t2.629697760976172\n",
      "  (17499, 2983)\t3.9866361567457265\n",
      "  (17499, 2749)\t4.183841646281483\n",
      "  (17499, 2264)\t5.004822198351313\n",
      "  (17499, 1868)\t4.403542853404719\n",
      "  (17499, 1356)\t1.4386950026070722\n",
      "  (17499, 1254)\t1.5900290491748739\n",
      "  (17499, 1042)\t4.824592692529582\n",
      "  (17499, 996)\t5.172355697247385\n",
      "  (17499, 210)\t5.0662308264799565\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X_train_tfidf.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t19.9286367482732\n",
      "  (0, 1)\t34.398364192335166\n",
      "  (0, 2)\t16.570213302696317\n",
      "  (0, 3)\t8.978253831908102\n",
      "  (0, 4)\t15.548562055164332\n",
      "  (0, 5)\t15.994849157792752\n",
      "  (0, 6)\t8.372118028337788\n",
      "  (0, 7)\t17.145577447599877\n",
      "  (0, 8)\t8.372118028337788\n",
      "  (0, 9)\t8.690571759456322\n",
      "  (0, 10)\t8.824103152080845\n",
      "  (0, 11)\t45.25228546877725\n",
      "  (0, 12)\t55.98824761330999\n",
      "  (0, 13)\t14.805434942299367\n",
      "  (0, 14)\t14.212903310013022\n",
      "  (0, 15)\t24.61519183102386\n",
      "  (0, 16)\t16.744236056675575\n",
      "  (0, 17)\t17.956507663816204\n",
      "  (0, 18)\t8.978253831908102\n",
      "  (0, 19)\t8.467428208142112\n",
      "  (0, 20)\t60.079201641084474\n",
      "  (0, 21)\t8.372118028337788\n",
      "  (0, 22)\t15.994849157792752\n",
      "  (0, 23)\t21.710716196685386\n",
      "  (0, 24)\t8.467428208142112\n",
      "  :\t:\n",
      "  (0, 22965)\t8.978253831908102\n",
      "  (0, 22966)\t35.91301532763241\n",
      "  (0, 22967)\t17.145577447599877\n",
      "  (0, 22968)\t8.690571759456322\n",
      "  (0, 22969)\t8.824103152080845\n",
      "  (0, 22970)\t16.570213302696317\n",
      "  (0, 22971)\t211.6857052035528\n",
      "  (0, 22972)\t64.49570480027158\n",
      "  (0, 22973)\t15.45098172682547\n",
      "  (0, 22974)\t82.0506394367462\n",
      "  (0, 22975)\t143.2669003949848\n",
      "  (0, 22976)\t61.105852978798886\n",
      "  (0, 22977)\t18.616995329004965\n",
      "  (0, 22978)\t8.690571759456322\n",
      "  (0, 22979)\t15.759283086479986\n",
      "  (0, 22980)\t17.956507663816204\n",
      "  (0, 22981)\t15.759283086479986\n",
      "  (0, 22982)\t8.690571759456322\n",
      "  (0, 22983)\t23.99227373668913\n",
      "  (0, 22984)\t65.04764777216718\n",
      "  (0, 22985)\t55.55759969955959\n",
      "  (0, 22986)\t33.869712832568446\n",
      "  (0, 22987)\t8.824103152080845\n",
      "  (0, 22988)\t16.934856416284223\n",
      "  (0, 22989)\t25.402284624426336\n"
     ]
    }
   ],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.92863675, 34.39836419, 16.5702133 , ...,  8.82410315,\n",
       "        16.93485642, 25.40228462]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_max_value_sorted = m.toarray().ravel().argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with lowest tfidf:\n",
      "['touches' 'poignant' 'briefly' 'importantly' 'root' 'instantly' 'wonders'\n",
      " 'scripted' 'lacked' 'currently' 'suited' 'undoubtedly' 'highest'\n",
      " 'disagree' 'draws' 'nearby' 'occurred' 'altogether' 'jealous' 'uneven']\n",
      "Features with highest tfidf: \n",
      "['gypo' 'luzhin' 'ripley' 'kornbluth' 'paulie' 'blob' 'homer' 'taker'\n",
      " 'dillinger' 'coop' 'vargas' 'gadget' 'dominick' 'jesse' 'bridget' 'the'\n",
      " 'victor' 'victoria' 'zizek' 'timon']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(tfidf.get_feature_names())\n",
    "print(\"Features with lowest tfidf:\\n{}\".format(\n",
    "feature_names[tfidf_max_value_sorted[:20]]))\n",
    "print(\"Features with highest tfidf: \\n{}\".format(\n",
    "feature_names[tfidf_max_value_sorted[-20:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with lowest idf:\n",
      "['the' 'and' 'of' 'to' 'this' 'is' 'it' 'in' 'that' 'but' 'for' 'with'\n",
      " 'was' 'as' 'on' 'movie' 'not' 'br' 'have' 'one' 'be' 'film' 'are' 'you'\n",
      " 'all' 'at' 'an' 'by' 'from' 'so' 'like' 'who' 'they' 'there' 'if' 'his'\n",
      " 'just' 'about' 'out' 'he' 'or' 'has' 'what' 'can' 'some' 'good' 'when'\n",
      " 'more' 'time' 'very' 'up' 'only' 'even' 'no' 'my' 'would' 'see' 'really'\n",
      " 'which' 'story' 'well' 'had' 'me' 'than' 'much' 'their' 'were' 'get'\n",
      " 'other' 'do' 'been' 'most' 'her' 'don' 'also' 'into' 'first' 'made' 'how'\n",
      " 'because' 'great' 'will' 'people' 'make' 'way' 'bad' 'we' 'could' 'any'\n",
      " 'after' 'too' 'then' 'them' 'she' 'think' 'watch' 'acting' 'movies'\n",
      " 'seen' 'its']\n"
     ]
    }
   ],
   "source": [
    "sorted_by_idf = np.argsort(tfidf.idf_)\n",
    "print(\"Features with lowest idf:\\n{}\".format(\n",
    "feature_names[sorted_by_idf[:100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = tfidf.transform(d_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.892\n"
     ]
    }
   ],
   "source": [
    "logreg = grid.best_estimator_.named_steps[\"logisticregression\"]\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[3315  424]\n",
      " [ 383 3378]]\n"
     ]
    }
   ],
   "source": [
    "pred_logreg = logreg.predict(X_test_tfidf)\n",
    "confusion = confusion_matrix(y_test, pred_logreg)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.902\n",
      "Test set score: 0.839\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(nb.score(X_train_tfidf, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(nb.score(X_test_tfidf, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[3249  490]\n",
      " [ 717 3044]]\n"
     ]
    }
   ],
   "source": [
    "pred_nb = nb.predict(X_test_tfidf)\n",
    "confusion = confusion_matrix(y_test, pred_nb)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000\n",
      "Test set score: 0.864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=1000,n_jobs=6)\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(rf.score(X_train_tfidf, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(rf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "review = \"This movie is not that good\"\n",
    "print(logreg.predict(tfidf.transform([review]))[0])\n",
    "\n",
    "print(rf.predict(tfidf.transform([review]))[0])\n",
    "\n",
    "print(nb.predict(tfidf.transform([review]))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "review = \"This movie is not that bad\"\n",
    "print(logreg.predict(tfidf.transform([review]))[0])\n",
    "\n",
    "print(rf.predict(tfidf.transform([review]))[0])\n",
    "\n",
    "print(nb.predict(tfidf.transform([review]))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "review = \"I was going to say something awesome or great or good, but I can't because the movie is so bad.\"\n",
    "print(logreg.predict(tfidf.transform([review]))[0])\n",
    "\n",
    "print(rf.predict(tfidf.transform([review]))[0])\n",
    "\n",
    "print(nb.predict(tfidf.transform([review]))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
