{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "import spacy\n",
    "import nltk\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = [\"The weather today is worse than yesterday\",\n",
    "           \"education is what you have left over after forgetting everything you ever learnt\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model = spacy.load('en')\n",
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_and_lemma(doc):\n",
    "    doc_spacy = en_model(doc)\n",
    "    print(\"Lemmatization:\")\n",
    "    print([token.lemma_ for token in doc_spacy])\n",
    "    print(\"Stemming:\")\n",
    "    print([stemmer.stem(token.norm_.lower()) for token in doc_spacy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization:\n",
      "['the', 'weather', 'today', 'be', 'bad', 'than', 'yesterday']\n",
      "Stemming:\n",
      "['the', 'weather', 'today', 'is', 'wors', 'than', 'yesterday']\n"
     ]
    }
   ],
   "source": [
    "stem_and_lemma(phrases[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization:\n",
      "['education', 'be', 'what', '-PRON-', 'have', 'leave', 'over', 'after', 'forget', 'everything', '-PRON-', 'ever', 'learn']\n",
      "Stemming:\n",
      "['educ', 'is', 'what', 'you', 'have', 'left', 'over', 'after', 'forget', 'everyth', 'you', 'ever', 'learnt']\n"
     ]
    }
   ],
   "source": [
    "stem_and_lemma(phrases[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/labeledTrainData.tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_split(data,y,length,split_mark=0.7):\n",
    "    if split_mark > 0. and split_mark < 1.0:\n",
    "        n = int(split_mark*length)\n",
    "    else:\n",
    "        n = int(split_mark)\n",
    "    X_train =  data[:n].copy()\n",
    "    X_test =   data[n:].copy()\n",
    "    y_train = y[:n].copy()\n",
    "    y_test  = y[n:].copy()\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(data):\n",
    "    d_train,d_test,y_train,y_test = simple_split(data,data.sentiment,len(data))\n",
    "    print(d_train.shape,d_test.shape,y_train.shape,y_test.shape)\n",
    "    pipe = make_pipeline(TfidfVectorizer(min_df=5, norm=None),LogisticRegression())\n",
    "    start = time()\n",
    "    param_dist = {\"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  \"tfidfvectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)]\n",
    "                 }\n",
    "    model = RandomizedSearchCV(pipe,param_dist, cv=5, n_iter=12)\n",
    "    model.fit(d_train.review, y_train)\n",
    "    print('RandomizedSearchCV Training took {} minutes'.format((time() - start)/60.))\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(model.best_score_))\n",
    "    print(\"Best parameters:\\n{}\".format(model.best_params_))\n",
    "    tfidf = model.best_estimator_.named_steps[\"tfidfvectorizer\"]\n",
    "    logreg = model.best_estimator_.named_steps[\"logisticregression\"]\n",
    "    pipe = make_pipeline(tfidf,logreg)\n",
    "    pipe.fit(d_train.review, y_train)\n",
    "    print(\"Test set score: {:.3f}\".format(pipe.score(d_test.review, y_test)))\n",
    "    pred_logreg = pipe.predict(d_test.review)\n",
    "    confusion = confusion_matrix(y_test, pred_logreg)\n",
    "    print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "    return pipe\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(doc):\n",
    "    d1 = en_model(doc)\n",
    "    d1 = ' '.join([token.lemma_ for token in d1])\n",
    "    return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmatize(doc):\n",
    "    d1 = en_model(doc)\n",
    "    d1 = ' '.join([stemmer.stem(token.norm_.lower()) for token in d1])\n",
    "    return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization took 99.19152934948603 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "data['review'] = data['review'].apply(lemmatize)\n",
    "print('Lemmatization took {} minutes'.format((time() - start)/60.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500, 3) (7500, 3) (17500,) (7500,)\n",
      "RandomizedSearchCV Training took 42.26202932993571 minutes\n",
      "Best cross-validation score: 0.90\n",
      "Best parameters:\n",
      "{'tfidfvectorizer__ngram_range': (1, 3), 'logisticregression__C': 0.001}\n",
      "Test set score: 0.900\n",
      "Confusion matrix:\n",
      "[[3346  393]\n",
      " [ 355 3406]]\n"
     ]
    }
   ],
   "source": [
    "lemm = sentiment_analysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/labeledTrainData.tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmatization took 105.80064667065939 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "data['review'] = data['review'].apply(stemmatize)\n",
    "print('Stemmatization took {} minutes'.format((time() - start)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500, 3) (7500, 3) (17500,) (7500,)\n",
      "RandomizedSearchCV Training took 40.914124596118924 minutes\n",
      "Best cross-validation score: 0.90\n",
      "Best parameters:\n",
      "{'tfidfvectorizer__ngram_range': (1, 3), 'logisticregression__C': 0.01}\n",
      "Test set score: 0.903\n",
      "Confusion matrix:\n",
      "[[3378  361]\n",
      " [ 365 3396]]\n"
     ]
    }
   ],
   "source": [
    "stem = sentiment_analysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "review = [\"This movie is not that good\"]\n",
    "print(lemm.predict(review)[0])\n",
    "print(stem.predict(review)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "review = [\"This movie is not that bad\"]\n",
    "print(lemm.predict(review)[0])\n",
    "print(stem.predict(review)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "review = [\"I was going to say something awesome or great or good, but I can't because the movie is so bad.\"]\n",
    "print(lemm.predict(review)[0])\n",
    "print(stem.predict(review)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
