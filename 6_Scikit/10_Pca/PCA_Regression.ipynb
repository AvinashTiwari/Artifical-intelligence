{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from scipy.stats import skew\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "%load_ext autoreload\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_columns_by_type(df):\n",
    "    out = []\n",
    "    for colname, col_values in df.items():\n",
    "        if is_string_dtype(col_values):\n",
    "            out.append((colname,'string') )\n",
    "        elif not is_numeric_dtype(col_values):\n",
    "            out.append((colname,'categorical') )\n",
    "    return out\n",
    "       \n",
    "def get_missing_values_percentage(df):\n",
    "    missing_values_counts_list = df.isnull().sum()\n",
    "    total_values = np.product(df.shape)\n",
    "    total_missing = missing_values_counts_list.sum()\n",
    "    # percent of data that is missing\n",
    "    return (total_missing/total_values) * 100\n",
    "\n",
    "def get_missing_columns(df1,df2):\n",
    "    missing1 = []\n",
    "    missing2 = []\n",
    "    for colname in df1.columns:\n",
    "        if colname not in df2.columns:\n",
    "            missing2.append(colname)\n",
    "    for colname in df2.columns:\n",
    "        if colname not in df1.columns:\n",
    "            missing1.append(colname)        \n",
    "    return (missing1,missing2)\n",
    "\n",
    "\n",
    "def handle_missing_values(df_in, na_dict=None, inplace=True):\n",
    "    if(inplace):\n",
    "        df = df_in\n",
    "    else:\n",
    "        df = df_in.copy()\n",
    " \n",
    "    if na_dict is None:\n",
    "        na_dict = {}\n",
    "\n",
    "    for colname, col_values in df.items():\n",
    "        if colname in na_dict:\n",
    "            if na_dict[colname] == 'drop_rows':\n",
    "                df.dropna(subset=[colname], inplace=True)\n",
    "                continue\n",
    "            elif na_dict[colname] == 'drop_col':\n",
    "                df.drop(colname, axis=1, inplace=True)\n",
    "                continue\n",
    "\n",
    "        if is_numeric_dtype(col_values):\n",
    "            if pd.isnull(col_values).sum():\n",
    "                df[colname+'_na'] = pd.isnull(col_values)\n",
    "                filler = na_dict[colname] if colname in na_dict else col_values.median()\n",
    "                df[colname] = col_values.fillna(filler)\n",
    "                na_dict[colname] = filler\n",
    "    return (df,na_dict)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATH = \"iowa/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid switch - \"\".\n"
     ]
    }
   ],
   "source": [
    "!dir {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission1.csv', 'test.csv', 'train.csv']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(f'{PATH}train.csv', low_memory=False)\n",
    "df_test = pd.read_csv(f'{PATH}test.csv', low_memory=False)\n",
    "df = df_raw.copy()\n",
    "df_id = df['Id']\n",
    "test_id = df_test['Id']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1458, 80) (1459, 79)\n"
     ]
    }
   ],
   "source": [
    "df.drop(\"Id\", axis = 1, inplace = True)\n",
    "df_test.drop(\"Id\", axis = 1, inplace = True)\n",
    "df = df.drop(df[(df['GrLivArea']>4000) & (df['SalePrice']<300000)].index)\n",
    "print(df.shape,df_test.shape)\n",
    "\n",
    "ntrain = df.shape[0]\n",
    "ntest = df_test.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avinash.t\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "combined = pd.concat((df, df_test)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['SalePrice']\n",
    "y = np.log1p(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2917, 80)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2917, 82), (1458, 80), (1459, 79), (1458,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['TotalArea'] = combined['TotalBsmtSF'] + combined['1stFlrSF'] + combined['2ndFlrSF']\n",
    "combined[\"TotalSF\"] = combined[\"GrLivArea\"] + combined[\"TotalBsmtSF\"]\n",
    "combined.shape,df.shape,df_test.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice        1.000000\n",
       "TotalArea        0.832877\n",
       "TotalSF          0.829042\n",
       "OverallQual      0.795774\n",
       "GrLivArea        0.734968\n",
       "TotalBsmtSF      0.651153\n",
       "GarageCars       0.641047\n",
       "1stFlrSF         0.631530\n",
       "GarageArea       0.629217\n",
       "FullBath         0.562165\n",
       "TotRmsAbvGrd     0.537769\n",
       "YearBuilt        0.523608\n",
       "YearRemodAdd     0.507717\n",
       "GarageYrBlt      0.487156\n",
       "MasVnrArea       0.482719\n",
       "Fireplaces       0.469862\n",
       "BsmtFinSF1       0.409384\n",
       "LotFrontage      0.370584\n",
       "WoodDeckSF       0.324758\n",
       "OpenPorchSF      0.321142\n",
       "2ndFlrSF         0.320532\n",
       "HalfBath         0.284590\n",
       "LotArea          0.268179\n",
       "BsmtFullBath     0.228459\n",
       "BsmtUnfSF        0.214460\n",
       "BedroomAbvGr     0.168245\n",
       "ScreenPorch      0.111415\n",
       "PoolArea         0.099490\n",
       "MoSold           0.046124\n",
       "3SsnPorch        0.044568\n",
       "BsmtFinSF2      -0.011422\n",
       "BsmtHalfBath    -0.016881\n",
       "MiscVal         -0.021203\n",
       "LowQualFinSF    -0.025625\n",
       "YrSold          -0.028882\n",
       "OverallCond     -0.077948\n",
       "MSSubClass      -0.084276\n",
       "EnclosedPorch   -0.128646\n",
       "KitchenAbvGr    -0.135946\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = combined.corr()\n",
    "cor[\"SalePrice\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.drop('SalePrice',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew in numerical features: \n",
      "\n",
      "There are 38 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "numeric_feats = combined.dtypes[combined.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = combined[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    combined[feat] = boxcox1p(combined[feat], lam)\n",
    "    \n",
    "#combined[skewed_features] = np.log1p(combined[skewed_features])\n",
    "\n",
    "#skewness.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolQC           2908\n",
       "MiscFeature      2812\n",
       "Alley            2719\n",
       "Fence            2346\n",
       "FireplaceQu      1420\n",
       "LotFrontage       486\n",
       "GarageCond        159\n",
       "GarageFinish      159\n",
       "GarageQual        159\n",
       "GarageYrBlt       159\n",
       "GarageType        157\n",
       "BsmtCond           82\n",
       "BsmtExposure       82\n",
       "BsmtQual           81\n",
       "BsmtFinType2       80\n",
       "BsmtFinType1       79\n",
       "MasVnrType         24\n",
       "MasVnrArea         23\n",
       "MSZoning            4\n",
       "BsmtFullBath        2\n",
       "BsmtHalfBath        2\n",
       "Functional          2\n",
       "Utilities           2\n",
       "Electrical          1\n",
       "TotalArea           1\n",
       "KitchenQual         1\n",
       "Exterior2nd         1\n",
       "Exterior1st         1\n",
       "TotalSF             1\n",
       "GarageCars          1\n",
       "                 ... \n",
       "OverallCond         0\n",
       "YrSold              0\n",
       "YearRemodAdd        0\n",
       "YearBuilt           0\n",
       "WoodDeckSF          0\n",
       "TotRmsAbvGrd        0\n",
       "Street              0\n",
       "ScreenPorch         0\n",
       "SaleCondition       0\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "PoolArea            0\n",
       "PavedDrive          0\n",
       "OverallQual         0\n",
       "OpenPorchSF         0\n",
       "HalfBath            0\n",
       "Neighborhood        0\n",
       "MoSold              0\n",
       "MiscVal             0\n",
       "MSSubClass          0\n",
       "LowQualFinSF        0\n",
       "LotShape            0\n",
       "LotConfig           0\n",
       "LotArea             0\n",
       "LandSlope           0\n",
       "LandContour         0\n",
       "KitchenAbvGr        0\n",
       "HouseStyle          0\n",
       "HeatingQC           0\n",
       "1stFlrSF            0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'is_numeric_dtype' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-3644143b316e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mcombined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mcombined\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_missing_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mget_missing_values_percentage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-3d1e45cbef0d>\u001b[0m in \u001b[0;36mhandle_missing_values\u001b[1;34m(df_in, na_dict, inplace)\u001b[0m\n\u001b[0;32m     45\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mis_numeric_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolname\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_na'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'is_numeric_dtype' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "combined['MSSubClass'] = combined['MSSubClass'].apply(str)\n",
    "combined['OverallCond'] = combined['OverallCond'].astype(str)\n",
    "combined['YrSold'] = combined['YrSold'].astype(str)\n",
    "combined['MoSold'] = combined['MoSold'].astype(str)\n",
    "combined['YearBuilt'] = combined['YearBuilt'].astype(str)\n",
    "combined['YearRemodAdd'] = combined['YearRemodAdd'].astype(str)\n",
    "\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(combined[c].values)) \n",
    "    combined[c] = lbl.transform(list(combined[c].values))\n",
    "\n",
    "combined = pd.get_dummies(combined)\n",
    "combined,_ = handle_missing_values(combined,inplace=False)\n",
    "get_missing_values_percentage(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1458, 398), (1459, 398))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = combined[:ntrain]\n",
    "df_test = combined[ntrain:]\n",
    "df.shape,df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_valid,y_train,y_valid = train_test_split(df,y,test_size=0.15,\n",
    "                                  stratify=df['OverallQual'],shuffle = True,random_state=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler().fit(X_train)\n",
    "X_train_robust = scaler.transform(X_train)\n",
    "X_valid_robust = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-0e4edf480ad4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlasso_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLasso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0.0005\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlasso_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_robust\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasso_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid_robust\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"R2 score: {:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, check_input)\u001b[0m\n\u001b[0;32m    711\u001b[0m             X, y = check_X_y(X, y, accept_sparse='csc',\n\u001b[0;32m    712\u001b[0m                              \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m                              copy=X_copied, multi_output=True, y_numeric=True)\n\u001b[0m\u001b[0;32m    714\u001b[0m             y = check_array(y, order='F', copy=False, dtype=X.dtype.type,\n\u001b[0;32m    715\u001b[0m                             ensure_2d=False)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "lasso_model = Lasso(alpha =0.0005,max_iter=100000,random_state=100)\n",
    "lasso_model.fit(X_train_robust,y_train)\n",
    "predictions = lasso_model.predict(X_valid_robust)\n",
    "print(mean_squared_error(np.log(y_valid),np.log(predictions)))\n",
    "print(\"R2 score: {:.2f}\".format(r2_score(y_valid,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_accuracy(model,train,test,ytrain,ytest,scorer,crange=None,\n",
    "                      scaler=None):\n",
    "    components = []\n",
    "    scores = []\n",
    "    if scaler is None:\n",
    "        scaler_ = RobustScaler()\n",
    "    else:\n",
    "        scaler_ = scaler\n",
    "        \n",
    "    for c in range(crange[0],crange[1],crange[2]):\n",
    "        pca = PCA(n_components=c,whiten=True, random_state=0).fit(train)\n",
    "        Xt = pca.transform(train)\n",
    "        Xv = pca.transform(test)\n",
    "        scaler_ = scaler_.fit(Xt)\n",
    "        Xtrain_transformed = scaler_.transform(Xt)\n",
    "        Xvalid_transformed = scaler_.transform(Xv)\n",
    "        model.fit(Xtrain_transformed,ytrain)\n",
    "        preds = model.predict(Xvalid_transformed)\n",
    "        if scorer is not None:\n",
    "            score = scorer(ytest,preds)\n",
    "        else:\n",
    "            score = model.score(ytest,preds)\n",
    "            \n",
    "        scores.append(score)\n",
    "        components.append(c)\n",
    "    \n",
    "    plt.plot(components,scores,label=\"train accuracy\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.xlabel(\"Components\")\n",
    "    \n",
    "plot_pca_accuracy(Lasso(alpha =0.0005,max_iter=100000,random_state=100),\n",
    "                  X_train,X_valid,y_train,y_valid,mean_squared_error,\n",
    "                  (90,200,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=144, whiten=True, random_state=0).fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_valid_pca = pca.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "dimensions = np.argmax(cumsum >= 0.99) + 1\n",
    "dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-0a85deed7b05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlasso_model_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLasso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0.0005\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlasso_model_pca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasso_model_pca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"R2 score: {:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_pca' is not defined"
     ]
    }
   ],
   "source": [
    "lasso_model_pca = Lasso(alpha =0.0005,max_iter=100000,random_state=100)\n",
    "lasso_model_pca.fit(X_train_pca,y_train)\n",
    "predictions = lasso_model_pca.predict(X_valid_pca)\n",
    "print(mean_squared_error(np.log(y_valid),np.log(predictions)))\n",
    "print(\"R2 score: {:.2f}\".format(r2_score(y_valid,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pca = pca.transform(df_test)\n",
    "predictions = np.expm1(lasso_model_pca.predict(df_test_pca))\n",
    "df_submit = pd.DataFrame({'Id':test_id, 'SalePrice': pd.Series(predictions)},\n",
    "              columns=['Id', 'SalePrice'])\n",
    "df_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_submit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2248286a64b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_submit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mysubmission.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%.6f'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_submit' is not defined"
     ]
    }
   ],
   "source": [
    "df_submit.to_csv('mysubmission.csv',index=False,float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
