# -*- coding: utf-8 -*-
"""Creating Image classification API with TensorFlow Serving.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ceIuwcbMDImuxbkmid3qi21sJW8Xbrun

## Stage 1: Install dependencies and setting up GPU environment
"""

!echo "deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -

!apt-get update & apt-get install tensorflow-model-server

!pip install tensorflow-gpu==1.13.1

!pip install requests

"""## Stage 2: Import project dependencies"""

# Commented out IPython magic to ensure Python compatibility.
import os
import json
import random
import requests
import subprocess
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

from tensorflow.keras.datasets import cifar10

# %matplotlib inline
tf.__version__

"""## Stage 3: Dataset preprocessing

### Loading the dataset
"""

(X_train, y_train), (X_test, y_test) = cifar10.load_data()

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

"""### Image normalization"""

X_train = X_train / 255.0
X_test = X_test / 255.0

X_train.shape

"""## Stage 4: Defining the model

NOTE: We are using the model from the Section for Convolutional neural networks
"""

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding="same", activation="relu", input_shape=[32, 32, 3]))
model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding="same", activation="relu"))
model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))
model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding="same", activation="relu"))
model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding="same", activation="relu"))
model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(units=128, activation='relu'))
model.add(tf.keras.layers.Dense(units=10, activation='softmax'))

"""### Compiling the model"""

model.compile(optimizer='Adam', 
              loss='sparse_categorical_crossentropy', 
              metrics=['sparse_categorical_accuracy'])

"""### Training the model"""

model.fit(X_train, 
          y_train, 
          batch_size=128, 
          epochs=10)

"""### Model evaluation"""

test_loss, test_accuracy = model.evaluate(X_test, y_test)

print("Test accuracy is {}".format(test_accuracy))

"""## Stage 5: Saving the model for production

### Creating the directory for the model
"""

MODEL_DIR = "model/"
version = 1

export_path = os.path.join(MODEL_DIR, str(version))
export_path

if os.path.isdir(export_path):
    !rm -r {export_path}

"""### Saving the model for the TensorFlow Serving"""

tf.saved_model.simple_save(tf.keras.backend.get_session(), export_dir=export_path, inputs={"input_image":model.input}, outputs={t.name:t for t in model.outputs})

"""## Stage 6: Setting up the production environment

### Exporting the MODEL_DIR to environment variables
"""

os.environ['MODEL_DIR'] = os.path.abspath(MODEL_DIR)

"""### Running the TensorFlow Serving REST API"""

# Commented out IPython magic to ensure Python compatibility.
# %%bash --bg
# nohup tensorflow_model_server --rest_api_port=8501 --model_name=cifar10 --model_base_path="${MODEL_DIR}" >server.log 2>&1

!tail server.log

"""## Stage 7: Creating the first POST request"""

random_image = np.random.randint(0, len(X_test))
random_image

"""### Creating the JSON data object"""

data = json.dumps({"signature_name":"serving_default", "instances":[X_test[random_image].tolist()]})

data

"""### Sending the first POST request to the model"""

headers = {"content-type":"application/json"}

json_response = requests.post(url="http://localhost:8501/v1/models/cifar10:predict", data=data, headers=headers)

json_response

predictions = json.loads(json_response.text)['predictions']

predictions

plt.imshow(X_test[random_image])

class_names[np.argmax(predictions[0])]

"""## Stage 8: Sending the POST request to a specific model"""

specific_json_response = requests.post(url="http://localhost:8501/v1/models/cifar10/versions/1:predict", data=data, headers=headers)

specific_json_response

